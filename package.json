{
  "name": "openai-chat",
  "publisher": "cweijan",
  "displayName": "OpenAI Chat",
  "icon": "images/chatgpt.png",
  "description": "Chat via OpenAI-Compatible API",
  "version": "5.0.0",
  "aiKey": "",
  "repository": {
    "url": "https://github.com/vscode-ext-studio/openai-chat"
  },
  "engines": {
    "vscode": "^1.96.0"
  },
  "categories": [
    "AI",
    "Machine Learning",
    "Testing",
    "Data Science",
    "Formatters",
    "Programming Languages",
    "Linters",
    "Chat"
  ],
  "keywords": [
    "AI",
    "chatgpt",
    "copilot",
    "agent",
    "Claude",
    "gpt",
    "gpt4",
    "llm",
    "openai",
    "Gemini",
    "Llama",
    "Ollama",
    "testing",
    "find bugs"
  ],
  "activationEvents": [
    "onStartupFinished"
  ],
  "main": "./out/extension.js",
  "contributes": {
    "menus": {
      "editor/context": [
        {
          "command": "openai-chat.generateCode",
          "group": "chatGpt@1",
          "when": "editorHasSelection && generateCode-enabled"
        },
        {
          "command": "openai-chat.addTests",
          "group": "chatGpt@2",
          "when": "editorHasSelection && addTests-enabled"
        },
        {
          "command": "openai-chat.findProblems",
          "group": "chatGpt@3",
          "when": "editorHasSelection && findProblems-enabled"
        },
        {
          "command": "openai-chat.optimize",
          "group": "chatGpt@4",
          "when": "editorHasSelection && optimize-enabled"
        },
        {
          "command": "openai-chat.explain",
          "group": "chatGpt@5",
          "when": "editorHasSelection && explain-enabled"
        },
        {
          "command": "openai-chat.addComments",
          "group": "chatGpt@6",
          "when": "editorHasSelection && addComments-enabled"
        },
        {
          "command": "openai-chat.completeCode",
          "group": "chatGpt@7",
          "when": "editorHasSelection && completeCode-enabled"
        },
        {
          "command": "openai-chat.adhoc",
          "group": "chatGpt@8",
          "when": "editorHasSelection && adhoc-enabled"
        },
        {
          "command": "openai-chat.customPrompt1",
          "group": "chatGpt@9",
          "when": "editorHasSelection && customPrompt1-enabled"
        },
        {
          "command": "openai-chat.customPrompt2",
          "group": "chatGpt@10",
          "when": "editorHasSelection && customPrompt2-enabled"
        }
      ],
      "view/title": [
        {
          "command": "openai-chat.openPromptManager",
          "when": "view == promptManager",
          "group": "navigation"
        },
        {
          "command": "openai-chat.openMCPServers",
          "when": "view == mcpServersView",
          "group": "navigation"
        }
      ]
    },
    "keybindings": [
      {
        "command": "openai-chat.generateCode",
        "key": "ctrl+shift+a",
        "mac": "cmd+shift+a",
        "when": "editorHasSelection"
      },
      {
        "command": "openai-chat.addTests",
        "key": "ctrl+k ctrl+shift+1",
        "mac": "cmd+k cmd+shift+1",
        "when": "editorHasSelection"
      },
      {
        "command": "openai-chat.findProblems",
        "key": "ctrl+k ctrl+shift+2",
        "mac": "cmd+k cmd+shift+2",
        "when": "editorHasSelection"
      },
      {
        "command": "openai-chat.optimize",
        "key": "ctrl+k ctrl+shift+3",
        "mac": "cmd+k cmd+shift+3",
        "when": "editorHasSelection"
      },
      {
        "command": "openai-chat.explain",
        "key": "ctrl+k ctrl+shift+4",
        "mac": "cmd+k cmd+shift+4",
        "when": "editorHasSelection"
      },
      {
        "command": "openai-chat.addComments",
        "key": "ctrl+k ctrl+shift+5",
        "mac": "cmd+k cmd+shift+5",
        "when": "editorHasSelection"
      },
      {
        "command": "openai-chat.completeCode",
        "key": "ctrl+k ctrl+shift+6",
        "mac": "cmd+k cmd+shift+6",
        "when": "editorHasSelection"
      },
      {
        "command": "openai-chat.adhoc",
        "key": "ctrl+k ctrl+shift+7",
        "mac": "cmd+k cmd+shift+7",
        "when": "editorHasSelection"
      },
      {
        "command": "openai-chat.customPrompt1",
        "key": "ctrl+k ctrl+shift+8",
        "mac": "cmd+k cmd+shift+8",
        "when": "editorHasSelection"
      },
      {
        "command": "openai-chat.customPrompt2",
        "key": "ctrl+k ctrl+shift+9",
        "mac": "cmd+k cmd+shift+9",
        "when": "editorHasSelection"
      }
    ],
    "commands": [
      {
        "command": "openai-chat.freeText",
        "title": "ChatGPT: Ask anything"
      },
      {
        "command": "openai-chat.clearSession",
        "title": "ChatGPT: Reset session"
      },
      {
        "command": "openai-chat.generateCode",
        "title": "ChatGPT-Codex: Generate code",
        "enablement": "editorHasSelection"
      },
      {
        "command": "openai-chat.addTests",
        "title": "ChatGPT: Add tests",
        "enablement": "editorHasSelection"
      },
      {
        "command": "openai-chat.findProblems",
        "title": "ChatGPT: Find bugs",
        "enablement": "editorHasSelection"
      },
      {
        "command": "openai-chat.optimize",
        "title": "ChatGPT: Optimize",
        "enablement": "editorHasSelection"
      },
      {
        "command": "openai-chat.explain",
        "title": "ChatGPT: Explain",
        "enablement": "editorHasSelection"
      },
      {
        "command": "openai-chat.addComments",
        "title": "ChatGPT: Add comments",
        "enablement": "editorHasSelection"
      },
      {
        "command": "openai-chat.completeCode",
        "title": "ChatGPT: Complete code",
        "enablement": "editorHasSelection"
      },
      {
        "command": "openai-chat.adhoc",
        "title": "ChatGPT: Ad-hoc prompt",
        "enablement": "editorHasSelection"
      },
      {
        "command": "openai-chat.customPrompt1",
        "title": "ChatGPT: Custom prompt 1",
        "enablement": "editorHasSelection"
      },
      {
        "command": "openai-chat.customPrompt2",
        "title": "ChatGPT: Custom prompt 2",
        "enablement": "editorHasSelection"
      },
      {
        "command": "openai-chat.clearConversation",
        "title": "ChatGPT: Clear conversation"
      },
      {
        "command": "openai-chat.exportConversation",
        "title": "ChatGPT: Export conversation"
      },
      {
        "command": "openai-chat.managePrompts",
        "title": "ChatGPT: Manage Prompts"
      },
      {
        "command": "openai-chat.debugPrompts",
        "title": "ChatGPT: Debug Stored Prompts"
      },
      {
        "command": "openai-chat.togglePromptManager",
        "title": "ChatGPT: Toggle Prompt Manager"
      },
      {
        "command": "openai-chat.addCurrentFile",
        "title": "Add Current File to Chat Context",
        "category": "ChatGPT"
      },
      {
        "command": "openai-chat.openPromptManager",
        "title": "ChatGPT: Open Prompt Manager"
      },
      {
        "command": "openai-chat.openMCPServers",
        "title": "ChatGPT: Open MCP Servers"
      }
    ],
    "viewsContainers": {
      "activitybar": [
        {
          "id": "openai-chat-view-container",
          "title": "AI Chat",
          "icon": "images/chatgpt-tree.png"
        }
      ]
    },
    "views": {
      "openai-chat-view-container": [
        {
          "type": "webview",
          "id": "openai-chat.view",
          "name": "ChatGPT"
        }
      ]
    },
    "configuration": {
      "title": "ChatGPT",
      "properties": {
        "chatgpt.gpt3.provider": {
          "type": "string",
          "markdownDescription": "Provider of LLM.",
          "enum": [
            "Auto",
            "OpenAI",
            "Ollama",
            "Azure",
            "AzureAI",
            "Anthropic",
            "GitHubCopilot",
            "Google",
            "Mistral",
            "xAI",
            "Together",
            "DeepSeek",
            "Groq",
            "Perplexity",
            "OpenRouter"
          ],
          "markdownEnumDescriptions": [
            "Auto - Infer provider from model",
            "OpenAI - OpenAI and OpenAI-compatible providers",
            "Ollama - Ollama local provider",
            "Azure - Azure OpenAI AI",
            "AzureAI - Azure AI (non-OpenAI models)",
            "Anthropic - Anthropic claude provider",
            "GitHubCopilot - Github Copilot provider",
            "Google - Google Generative AI",
            "Mistral",
            "xAI",
            "Together",
            "DeepSeek",
            "Groq",
            "Perplexity",
            "OpenRouter"
          ],
          "default": "Auto",
          "order": 0
        },
        "chatgpt.gpt3.apiKey": {
          "type": "string",
          "markdownDescription": "API key of your LLM provider",
          "order": 1
        },
        "chatgpt.gpt3.apiBaseUrl": {
          "type": "string",
          "default": "https://api.openai.com/v1",
          "markdownDescription": "Optional override for the API base URL. Please start with `https://` without a trailing slash. The completions endpoint suffix is added internally, e.g. for reference: `${apiBaseUrl}/v1/completions`",
          "order": 2
        },
        "chatgpt.gpt3.organization": {
          "type": "string",
          "markdownDescription": "OpenAI Organization ID. [Documentation](https://beta.openai.com/docs/api-reference/requesting-organization).",
          "order": 8
        },
        "chatgpt.gpt3.model": {
          "type": "string",
          "enum": [
            "gpt-3.5-turbo",
            "gpt-3.5-turbo-1106",
            "gpt-3.5-turbo-0125",
            "gpt-3.5-turbo-instruct",
            "gpt-4",
            "gpt-4o",
            "gpt-4o-mini",
            "gpt-4-0314",
            "gpt-4-0613",
            "gpt-4-1106-preview",
            "gpt-4-vision-preview",
            "gpt-4-0125-preview",
            "gpt-4-turbo-preview",
            "gpt-4-32k",
            "gpt-4-32k-0314",
            "gpt-4-32k-0613",
            "gpt-4-turbo",
            "o1",
            "o1-mini",
            "o1-preview",
            "o3",
            "o3-mini",
            "claude-3-opus-20240229",
            "claude-3-sonnet-20240229",
            "claude-3-haiku-20240307",
            "claude-3-opus-latest",
            "claude-3-5-sonnet-20240620",
            "claude-3-5-sonnet-20241022",
            "claude-3-5-sonnet-latest",
            "claude-3-5-haiku-20241022",
            "claude-3-5-haiku-latest",
            "claude-3-7-sonnet-20250219",
            "claude-3-7-sonnet-latest",
            "gemini-1.5-flash",
            "gemini-1.5-pro",
            "gemini-exp-1206",
            "gemini-2.0-flash",
            "gemini-2.0-flash-exp",
            "gemini-2.0-flash-lite",
            "gemini-2.0-pro-exp-02-05",
            "gemini-2.0-flash-thinking-exp-01-21",
            "learnlm-1.5-pro-experimental",
            "grok-2-1212",
            "grok-2-vision-1212",
            "grok-vision-beta",
            "grok-beta",
            "deepseek-chat",
            "DeepSeek-V3",
            "deepseek-reasoner",
            "DeepSeek-R1",
            "custom"
          ],
          "default": "gpt-4o",
          "markdownDescription": "OpenAI models to use for your prompts. [Documentation](https://beta.openai.com/docs/models/models). \n\n**If you face 400 Bad Request please make sure you are using the right model for your integration method.** \n\nFor local or self-hosted LLMs compatible with OpenAI, you can select `custom` and specify your custom model name in `#chatgpt.gpt3.customModel#`.",
          "order": 4
        },
        "chatgpt.gpt3.customModel": {
          "type": "string",
          "default": "",
          "markdownDescription": "Specify your custom model name here if you selected `custom` in `#chatgpt.gpt3.model#`. This allows you to use a custom model name for local or self-hosted LLMs compatible with OpenAI.",
          "order": 5
        },
        "chatgpt.gpt3.maxTokens": {
          "type": "number",
          "default": 1024,
          "markdownDescription": "The maximum number of tokens to generate in the completion. \n\nThe token count of your prompt plus max_tokens cannot exceed the model's context length. Most models have a context length of 2048 tokens (except for the newest models, which support 4096). [Documentation](https://beta.openai.com/docs/api-reference/completions/create#completions/create-max_tokens)**",
          "order": 6
        },
        "chatgpt.gpt3.temperature": {
          "type": "number",
          "default": 1,
          "markdownDescription": "What sampling temperature to use. Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 (argmax sampling) for ones with a well-defined answer.\n\nIt is recommended altering this or top_p but not both. [Documentation](https://beta.openai.com/docs/api-reference/completions/create#completions/create-temperature)**",
          "order": 7
        },
        "chatgpt.gpt3.top_p": {
          "type": "number",
          "default": 1,
          "markdownDescription": "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. \n\nIt is recommended altering this or temperature but not both. [Documentation](https://beta.openai.com/docs/api-reference/completions/create#completions/create-top_p)**",
          "order": 8
        },
        "chatgpt.systemPrompt": {
          "type": "string",
          "default": "",
          "description": "System prompts for the copilot.",
          "order": 9
        },
        "chatgpt.gpt3.generateCode-enabled": {
          "type": "boolean",
          "default": true,
          "description": "Enable the code generation context menu item for the selected comment/code for Codex. Only available with code-* models.",
          "order": 10
        },
        "chatgpt.gpt3.searchGrounding.enabled": {
          "type": "boolean",
          "default": false,
          "description": "Enable search grounding for Gemini model. Only available for Google Gemini models.",
          "order": 11
        },
        "chatgpt.promptPrefix.addTests": {
          "type": "string",
          "default": "Implement tests for the following code",
          "description": "The prompt prefix used for adding tests for the selected code",
          "order": 31
        },
        "chatgpt.promptPrefix.addTests-enabled": {
          "type": "boolean",
          "default": true,
          "description": "Enable the prompt prefix used for adding tests for the selected code in the context menu",
          "order": 32
        },
        "chatgpt.promptPrefix.findProblems": {
          "type": "string",
          "default": "Find problems with the following code",
          "description": "The prompt prefix used for finding problems for the selected code",
          "order": 33
        },
        "chatgpt.promptPrefix.findProblems-enabled": {
          "type": "boolean",
          "default": true,
          "description": "Enable the prompt prefix used for finding problems for the selected code in the context menu",
          "order": 34
        },
        "chatgpt.promptPrefix.optimize": {
          "type": "string",
          "default": "Optimize the following code",
          "description": "The prompt prefix used for optimizing the selected code",
          "order": 35
        },
        "chatgpt.promptPrefix.optimize-enabled": {
          "type": "boolean",
          "default": true,
          "description": "Enable the prompt prefix used for optimizing the selected code in the context menu",
          "order": 36
        },
        "chatgpt.promptPrefix.explain": {
          "type": "string",
          "default": "Explain the following code",
          "description": "The prompt prefix used for explaining the selected code",
          "order": 37
        },
        "chatgpt.promptPrefix.explain-enabled": {
          "type": "boolean",
          "default": true,
          "description": "Enable the prompt prefix used for explaining the selected code in the context menu",
          "order": 38
        },
        "chatgpt.promptPrefix.addComments": {
          "type": "string",
          "default": "Add comments for the following code",
          "description": "The prompt prefix used for adding comments for the selected code",
          "order": 39
        },
        "chatgpt.promptPrefix.addComments-enabled": {
          "type": "boolean",
          "default": true,
          "description": "Enable the prompt prefix used for adding comments for the selected code in the context menu",
          "order": 40
        },
        "chatgpt.promptPrefix.completeCode": {
          "type": "string",
          "default": "Complete the following code",
          "description": "The prompt prefix used for completing the selected code",
          "order": 41
        },
        "chatgpt.promptPrefix.completeCode-enabled": {
          "type": "boolean",
          "default": true,
          "description": "Enable the prompt prefix used for completing the selected code in the context menu",
          "order": 42
        },
        "chatgpt.promptPrefix.adhoc-enabled": {
          "type": "boolean",
          "default": true,
          "description": "Enable the prompt prefix used for adhoc command for the selected code in the context menu",
          "order": 43
        },
        "chatgpt.promptPrefix.customPrompt1": {
          "type": "string",
          "default": "",
          "description": "Your custom prompt 1. It's disabled by default, please set to a custom prompt and enable it if you prefer using customized prompt",
          "order": 71
        },
        "chatgpt.promptPrefix.customPrompt1-enabled": {
          "type": "boolean",
          "default": false,
          "markdownDescription": "Enable custom prompt 1. If you enable this item make sure to set this `#chatgpt.promptPrefix.customPrompt1#`",
          "order": 72
        },
        "chatgpt.promptPrefix.customPrompt2": {
          "type": "string",
          "default": "",
          "description": "Your custom prompt 2. It's disabled by default, please set to a custom prompt and enable it if you prefer using customized prompt",
          "order": 73
        },
        "chatgpt.promptPrefix.customPrompt2-enabled": {
          "type": "boolean",
          "default": false,
          "markdownDescription": "Enable custom prompt 2. If you enable this item make sure to set this `#chatgpt.promptPrefix.customPrompt2#`",
          "order": 74
        },
        "chatgpt.response.showNotification": {
          "type": "boolean",
          "default": false,
          "description": "Choose whether you'd like to receive a notification when ChatGPT bot responds to your query.",
          "order": 91
        },
        "chatgpt.response.autoScroll": {
          "type": "boolean",
          "default": true,
          "description": "Whenever there is a new question or response added to the conversation window, extension will automatically scroll to the bottom. You can change that behaviour by disabling this setting.",
          "order": 92
        },
        "chatgpt.autoAddCurrentFile": {
          "type": "boolean",
          "default": true,
          "description": "Automatically add current file to chat context when switching files",
          "order": 122
        },
        "chatgpt.gpt3.reasoning.provider": {
          "type": "string",
          "markdownDescription": "[Reasoning Model] AI Provider.",
          "enum": [
            "Auto",
            "OpenAI",
            "Ollama",
            "Azure",
            "AzureAI",
            "Google",
            "DeepSeek",
            "Groq",
            "OpenRouter"
          ],
          "markdownEnumDescriptions": [
            "Auto - Infer provider from model",
            "OpenAI - OpenAI and OpenAI-compatible providers",
            "Ollama - Ollama local provider",
            "Azure - Azure OpenAI AI",
            "AzureAI - Azure AI (non-OpenAI models)",
            "Google - Google Generative AI",
            "DeepSeek",
            "Groq",
            "OpenRouter"
          ],
          "default": "Auto",
          "order": 150
        },
        "chatgpt.gpt3.reasoning.apiKey": {
          "type": "string",
          "markdownDescription": "[Reasoning Model] API Key.",
          "order": 151
        },
        "chatgpt.gpt3.reasoning.apiBaseUrl": {
          "type": "string",
          "default": "https://api.openai.com/v1",
          "markdownDescription": "[Reasoning Model] API Base URL.",
          "order": 152
        },
        "chatgpt.gpt3.reasoning.organization": {
          "type": "string",
          "markdownDescription": "[Reasoning Model] Organization (OpenAI only).",
          "order": 153
        },
        "chatgpt.gpt3.reasoning.model": {
          "type": "string",
          "default": "",
          "markdownDescription": "[Reasoning Model] Model to use for reasoning.",
          "order": 154
        },
        "chatgpt.gpt3.maxSteps": {
          "type": "number",
          "default": 15,
          "markdownDescription": "Max steps for agent mode (useful when using MCP servers).",
          "order": 155
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "rimraf out && yarn run esbuild-base --minify",
    "esbuild-base": "esbuild ./src/extension.ts --bundle --outfile=out/extension.js --external:vscode --format=cjs --platform=node",
    "build": "yarn run -S esbuild-base",
    "watch": "yarn run -S esbuild-base --sourcemap --watch",
    "fmt": "prettier --write \"src/**/*.ts\"&& yarn run test",
    "update": "npm install -g npm-check-updates && ncu -u && npm install",
    "test": "eslint src --ext ts && tsc --noEmit",
    "package": "vsce package --no-dependencies",
    "publish": "vsce publish --no-dependencies"
  },
  "devDependencies": {
    "@types/glob": "^8.1.0",
    "@types/isomorphic-fetch": "^0.0.39",
    "@types/mocha": "^10.0.10",
    "@types/node": "^22.13.10",
    "@types/uuid": "^10.0.0",
    "@types/vscode": "^1.96.0",
    "@types/vscode-webview": "^1.57.5",
    "@vscode/test-electron": "^2.4.1",
    "@vscode/vsce": "^3.3.0",
    "esbuild": "^0.25.1",
    "eslint": "^9.22.0",
    "glob": "^11.0.1",
    "mocha": "^11.1.0",
    "prettier": "^3.5.3",
    "ts-loader": "^9.5.2",
    "typescript": "^5.8.2",
    "webpack": "^5.98.0"
  },
  "dependencies": {
    "@ai-sdk/anthropic": "^1.1.17",
    "@ai-sdk/azure": "^1.2.5",
    "@ai-sdk/deepseek": "^0.1.15",
    "@ai-sdk/google": "^1.1.25",
    "@ai-sdk/groq": "^1.1.14",
    "@ai-sdk/mistral": "^1.1.17",
    "@ai-sdk/openai": "^1.2.5",
    "@ai-sdk/perplexity": "^1.0.7",
    "@ai-sdk/togetherai": "^0.1.16",
    "@ai-sdk/xai": "^1.1.15",
    "@modelcontextprotocol/sdk": "^1.7.0",
    "@openrouter/ai-sdk-provider": "^0.4.3",
    "@quail-ai/azure-ai-provider": "^1.0.5",
    "@types/minimatch": "^5.1.2",
    "ai": "^4.1.62",
    "ajv": "^8.17.1",
    "axios": "^1.8.3",
    "cheerio": "^1.0.0",
    "delay": "^6.0.0",
    "eventsource-parser": "^3.0.0",
    "gpt3-tokenizer": "^1.1.5",
    "isomorphic-fetch": "^3.0.0",
    "keyv": "^5.3.2",
    "minimatch": "^10.0.1",
    "ollama-ai-provider": "^1.2.0",
    "openai": "^4.87.4",
    "p-timeout": "^6.1.4",
    "punycode": "^2.3.1",
    "puppeteer": "^24.4.0",
    "puppeteer-extra": "^3.3.6",
    "puppeteer-extra-plugin-stealth": "^2.11.2",
    "puppeteer-extra-plugin-user-data-dir": "^2.4.1",
    "puppeteer-extra-plugin-user-preferences": "^2.4.1",
    "quick-lru": "^7.0.0",
    "remark": "^15.0.1",
    "strip-markdown": "^6.0.0",
    "uri-js": "^4.4.1",
    "uuid": "^11.1.0",
    "zod": "^3.24.2"
  },
  "resolutions": {
    "punycode": "2.3.1",
    "clone-deep": "^4.0.1"
  }
}